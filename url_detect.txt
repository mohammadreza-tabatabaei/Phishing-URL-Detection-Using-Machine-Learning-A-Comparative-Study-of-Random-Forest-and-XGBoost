# -*- coding: utf-8 -*-
"""URL DETECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Aniac9OYemOFlbegvTNNUIkNnyQWQykl
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
df = pd.read_csv("phishing-dataset-variation.csv")

# 3. Separate features and target variable
X = df.drop(columns=["phishing"])  # Drop the target column
y = df["phishing"]  # Target variable

# Impute missing values in features using the median strategy
imputer = SimpleImputer(strategy='median')
X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

# Verify that missing values are handled
print("Missing values after preprocessing:")
print(X.isnull().sum())

# Standardize the features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Train Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
rf_accuracy = accuracy_score(y_test, y_pred_rf)
print("Random Forest Accuracy:", rf_accuracy)
print("Random Forest Classification Report:")
print(classification_report(y_test, y_pred_rf))

# Train XGBoost model
xgb_model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)
xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)
xgb_accuracy = accuracy_score(y_test, y_pred_xgb)
print("XGBoost Accuracy:", xgb_accuracy)
print("XGBoost Classification Report:")
print(classification_report(y_test, y_pred_xgb))

# Compare model performance using a bar chart
metrics = ['Precision', 'Recall', 'Accuracy']
rf_scores = [0.98, 0.98, rf_accuracy]
xgb_scores = [0.97, 0.97, xgb_accuracy]

x = np.arange(len(metrics))
bar_width = 0.3

plt.figure(figsize=(8, 5))
plt.bar(x - bar_width/2, rf_scores, bar_width, label='Random Forest', color='royalblue')
plt.bar(x + bar_width/2, xgb_scores, bar_width, label='XGBoost', color='darkorange')
plt.xlabel("Metrics")
plt.ylabel("Scores")
plt.title("Model Performance Comparison")
plt.xticks(x, metrics)
plt.legend()
plt.ylim(0.95, 1)  # Focus on the relevant range
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()